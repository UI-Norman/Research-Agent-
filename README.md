# Credibility-Aware Research Agent for RND 

## ğŸ“‹ System Overview

This system evaluates information credibility in real-time, assigns scores, and takes dynamic actions to ensure factual accuracy in LLM research. It uses a hybrid approach combining heuristic analysis with LLM-based deep validation for optimal performance.

## ğŸ¯ Core Requirements Met

### âœ… Context-Specific Credibility
- **LOW** (self-interest bias detection)
- **MEDIUM** (valid insider info, context-aware)
- **LOW** (promotional language penalty)
- **HIGH** (evidence bonus, peer-reviewed)
- source consideration: Built into bias detection with adjustment range -4.0 to +2.0

### âœ… Dynamic Actions (LLM-Driven Final Decision)
- **Score â‰¥7.5**: INCLUDE (high credibility)
- **Score 4.5-7.4**: WARN (verification needed)
- **Score <4.5**: (low credibility)
- Final action determined by LLM considering score, source type, validation status, and context

### âœ… Incremental Updates (LLM-Guided Strategy)
- Conflict resolution based on credibility scores (highest priority)
- LLM analyzes update strategy (regenerate vs incremental)
- Smart merge with reconciliation for conflicts, reinforcements, and new info

### ğŸ“ Folder Architecture
credibility-research-agent/
â”‚
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ agent.py                    # Core ResearchAgent class
â”œâ”€â”€ credibility.py              # CredibilityAnalyzer with scoring logic
â”œâ”€â”€ tools.py                    # Search, extraction, validation utilities
â”œâ”€â”€ llm_factory.py              # LLM provider management (Gemini/Groq)
â”œâ”€â”€ config.py                   # Configuration and environment setup
â”œâ”€â”€ system_prompts.py           # All LLM prompts and system config
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (API keys)              
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ README.md                   # This file                  
â””â”€â”€ research_ai_ethics.txt

## ğŸ—ï¸ Solution Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              USER INTERFACE (app.py)                         â”‚
â”‚         Streamlit Web App for research & updates             â”‚
â”‚  - Model Selection (Gemini/Groq)                             â”‚
â”‚  - Research Execution                                        â”‚
â”‚  - File Upload for Updates                                   â”‚
â”‚  - Report Display & Download                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESEARCH AGENT (agent.py)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ LLM Integration via LLMFactory                       â”‚    â”‚
â”‚  â”‚ - Dynamic model selection (Gemini/Groq)              â”‚    â”‚
â”‚  â”‚ - System prompts for all operations                  â”‚    â”‚
â”‚  â”‚ - Caching with TTL (7200s)                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  Research Flow:                                              â”‚
â”‚  1. Web Search (tools.py) - Serper API or mock               â”‚
â”‚  2. Claim Extraction (LLM-based with prompt)                 â”‚
â”‚  3. Credibility Scoring (hybrid heuristic + LLM)             â”‚
â”‚  4. Batch Validation (parallel for low-medium scores)        â”‚
â”‚  5. Action Determination (LLM final decision)                â”‚
â”‚  6. Report Generation (LLM-based with prompt)                â”‚
â”‚                                                              â”‚
â”‚  Update Flow (LLM-Guided Incremental):                       â”‚
â”‚  1. Load cached claims                                       â”‚
â”‚  2. Extract new claims from uploaded file                    â”‚
â”‚  3. LLM analyzes update strategy                             â”‚
â”‚  4. Smart reconciliation (conflicts/reinforcements)          â”‚
â”‚  5. Merge with highest credibility priority                  â”‚
â”‚  6. Generate updated report                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
             â”‚              â”‚                              â”‚
             â–¼              â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  TOOLS     â”‚  â”‚ CREDIBILITY  â”‚         â”‚ SYSTEM PROMPTS   â”‚
    â”‚ (tools.py) â”‚  â”‚(credibility  â”‚         â”‚(system_prompts   â”‚
    â”‚            â”‚  â”‚    .py)      â”‚         â”‚     .py)         â”‚
    â”‚ - Search   â”‚  â”‚              â”‚         â”‚                  â”‚
    â”‚ - Extract  â”‚  â”‚ - Score      â”‚         â”‚ - Claim extract  â”‚
    â”‚ - Classify â”‚  â”‚ - LLM Decide â”‚         â”‚ - Validation     â”‚
    â”‚ - Validate â”‚  â”‚ - Bias LLM   â”‚         â”‚ - Bias detect    â”‚
    â”‚ - Batch    â”‚  â”‚ - Validate   â”‚         â”‚ - Final action   â”‚
    â”‚            â”‚  â”‚ - Action LLM â”‚         â”‚ - Reconcile      â”‚
    â”‚            â”‚  â”‚ - Heuristics â”‚         â”‚ - Report gen     â”‚
    â”‚            â”‚  â”‚ - Cache      â”‚         â”‚ - Update analyze â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    External Services     â”‚
              â”‚  - Serper API (search)   â”‚
              â”‚  - Google Gemini API     â”‚
              â”‚  - Groq API              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Configuration Layer    â”‚
              â”‚  - config.py             â”‚
              â”‚  - llm_factory.py        â”‚
              â”‚  - Environment vars      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Component Connections

### How System Prompts Connect to Files:

```
system_prompts.py
    â”‚
    â”œâ”€â–º agent.py
    â”‚   â””â”€ Uses: RECONCILIATION_PROMPT, REPORT_GENERATION_PROMPT, 
    â”‚            UPDATE_ANALYSIS_PROMPT, SUMMARY_PROMPT
    â”‚   â””â”€ Method: Format strings with context
    â”‚
    â”œâ”€â–º tools.py
    â”‚   â””â”€ Uses: CLAIM_EXTRACTION_PROMPT
    â”‚   â””â”€ Method: LLM invoke with formatted prompt
    â”‚
    â””â”€â–º credibility.py
        â””â”€ Uses: VALIDATION_DECISION_PROMPT, BIAS_DETECTION_PROMPT,
                 CLAIM_VALIDATION_PROMPT, FINAL_ACTION_PROMPT
        â””â”€ Method: LLM invoke with JSON response parsing
```

### File Interactions:

```
app.py (Streamlit UI)
  â””â”€â–º config.py (setup_environment)
       â”œâ”€â–º Load .env variables
       â”œâ”€â–º Validate API keys
       â””â”€â–º Return config dict
  â””â”€â–º llm_factory.py (LLMFactory)
       â”œâ”€â–º create_llm(provider, model)
       â””â”€â–º get_available_models(config)
  â””â”€â–º agent.py (ResearchAgent)
       â”œâ”€â–º research(topic)
       â”‚    â”œâ”€â–º tools.search_web()
       â”‚    â”œâ”€â–º tools.extract_claims() â†’ system_prompts.py
       â”‚    â”œâ”€â–º credibility.score_claim() â†’ system_prompts.py
       â”‚    â”œâ”€â–º tools.batch_validate_claims()
       â”‚    â”œâ”€â–º credibility.validate_claim() â†’ system_prompts.py
       â”‚    â”œâ”€â–º credibility.get_final_action() â†’ system_prompts.py
       â”‚    â””â”€â–º _generate_report() â†’ system_prompts.py
       â””â”€â–º update_research(filepath)
            â”œâ”€â–º tools.extract_claims()
            â”œâ”€â–º credibility.score_claim()
            â”œâ”€â–º _llm_update_strategy() â†’ system_prompts.py
            â”œâ”€â–º _smart_merge() â†’ system_prompts.py
            â””â”€â–º _generate_report() â†’ system_prompts.py
```

## ğŸ“Š Agent Design

### Research Agent States:
1. **IDLE**: Waiting for query
2. **SEARCHING**: Fetching web sources (Serper API)
3. **EXTRACTING**: LLM-based claim extraction (parallel processing)
4. **SCORING**: Hybrid credibility evaluation
5. **VALIDATING**: Batch validation for low-medium scores
6. **DECIDING**: LLM determines final actions
7. **REPORTING**: LLM-generated comprehensive report
8. **UPDATING**: Incremental research with LLM-guided strategy

### Credibility Scoring Flow:
```
Claim â†’ Source Classification (tools.py)
  â†“
Base Score (source weight Ã— 10)
  â†“
Heuristic Analysis (credibility.py)
  â”œâ”€ Promotional Detection (-1.5 per pattern, max -4)
  â”œâ”€ Absolute Language (-0.7 per word, max -3)
  â”œâ”€ Self-Interest Detection (-3.0 to -5.0)
  â””â”€ Evidence Bonus (+1.0 to +4.0)
  â†“
LLM Decision (needs_deep_analysis?)
  â”œâ”€ High (>7.5) or Low (<3.5): Skip deep analysis
  â”œâ”€ Borderline (3.5-7.5): Deep analysis required
  â””â”€ Conflicting signals: Deep analysis required
  â†“
If Deep Analysis:
  â””â”€ LLM Bias Detection â†’ Adjustment (-4.0 to +2.0)
  â†“
Final Score (0-10, clamped)
  â†“
Validation (if score < 4.5)
  â””â”€ Cross-reference with search evidence
  â””â”€ LLM verdict: SUPPORTS/CONTRADICTS/NEUTRAL
  â””â”€ Score adjustment (-4.0 to +2.0)
  â†“
LLM Final Action Decision
  â”œâ”€ INCLUDE (â‰¥7.5)
  â””â”€ WARN (4.5-7.4)
```
## ğŸ¯ Goals & KPIs

### Primary Goals:
1. **Accuracy**: >80% of included claims should be verifiable
2. **Efficiency**: <60s for initial research, <20s for updates
3. **Reliability**: Average credibility score >6.5/10
4. **Source Diversity**: â‰¥3 different source types per research
5. **Update Efficiency**: <30% overhead vs full research

### Measurable KPIs:

| KPI | Target | Implementation |
|-----|--------|----------------|
| Avg Credibility Score | â‰¥6.5 | `_calc_avg(claims)` in agent.py |
| High-Cred Ratio | â‰¥60% | Claims with score â‰¥7.5 |
| Processing Time | <60s | Tracked via `time.time()` |
| Update Overhead | <30% | `overhead_ratio` calculation |
| Source Diversity | â‰¥3 types | `classify_source()` tracking |
| Cache Hit Rate | â‰¥40% | TTLCache in credibility & agent |
| Parallel Efficiency | â‰¥50% speedup | ThreadPoolExecutor usage |

### Performance Metrics Tracked:
- **research_time**: Initial research duration
- **update_time**: Incremental update duration
- **overhead_ratio**: Update time / research time
- **sources_count**: Number of sources analyzed
- **overall_credibility**: Weighted average of included claims

## ğŸš¨ Edge Cases Handled

### 1. Conflicting Claims
**Scenario**: New source contradicts existing high-credibility claim  
**Solution**: LLM reconciliation with `RECONCILIATION_PROMPT`, prioritizes highest credibility score

### 2. Biased High-Authority Source
**Scenario**: .edu domain but funded by interested party  
**Solution**: 
- `_detect_self_interest()` applies -3.5 penalty for 'sponsored'
- LLM bias detection overrides source weight bonus
- Adjustment range: -4.0 to +2.0

### 3. Context Ambiguity
**Scenario**: Unclear if CEO statement is self-promotional  
**Solution**: 
- `VALIDATION_DECISION_PROMPT` triggers deep analysis for borderline scores
- LLM evaluates context with confidence scoring
- Conservative fallback if parsing fails

### 4. No Web Access
**Scenario**: Serper API fails or SERPER_API_KEY not set  
**Solution**: 
- `_mock_search()` provides fallback data
- Warning message in config setup
- Graceful degradation with mock academic/news/corporate/commercial sources

### 5. Malformed Claims
**Scenario**: LLM returns invalid JSON  
**Solution**: 
- Try-except blocks with fallback to sentence splitting
- Basic scoring applied (source weight only)
- Logged for debugging, no crash

### 6. Update Conflicts
**Scenario**: New file has 100% contradictory claims  
**Solution**: 
- `UPDATE_ANALYSIS_PROMPT` evaluates conflict percentage
- >25% conflicts triggers 'regenerate' strategy
- `_smart_merge()` keeps both, user sees reasoning
- Higher credibility scores prioritized in report

### 7. Source Classification Failure
**Scenario**: Unknown domain type  
**Solution**: 
- Default to 'corporate' (0.5 weight)
- Maintains system stability
- Prevents zero-score edge case

### 8. Cache Expiry During Update
**Scenario**: Cache TTL expires between research and update  
**Solution**:
- 7200s (2 hour) TTL sufficient for typical workflows
- Cache miss triggers re-research with warning
- User can re-run initial research if needed

## ğŸ’° Strategy Review

### Scaling Strategy

#### Phase 1: Single Instance (Current)
- **Handles**: ~100 requests/day
- **Cost**: ~$15/month (Gemini Flash + Serper API)
- **Infrastructure**: Single Streamlit instance
- **Cache**: In-memory TTLCache (7200s)

#### Phase 2: Horizontal Scaling (Month 2-3)
- **Add**: Redis cache (60% API call reduction)
- **Add**: PostgreSQL (persist research history)
- **Add**: Nginx load balancer
- **Handles**: ~10K requests/day
- **Cost**: ~$150/month
- **Deploy**: Docker Compose

#### Phase 3: Microservices (Month 4-6)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API GW    â”‚
â”‚  (FastAPI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼        â–¼        â–¼         â–¼          â–¼
Search  Extract  Score   Validate  Report
Service Service Service  Service   Service
(Serper) (LLM)  (Hybrid)  (LLM)    (LLM)
   â”‚        â”‚        â”‚         â”‚          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
    Redis Cache + PostgreSQL
         (Persistent Storage)
```
- **Handles**: ~100K requests/day
- **Cost**: ~$600/month
- **Deploy**: Kubernetes (GKE/EKS)

#### Phase 4: Enterprise (Month 7+)
- Multi-region deployment (US, EU, Asia)
- Custom fine-tuned models
- White-label options
- **Handles**: ~1M requests/day
- **Cost**: ~$2.5K/month

### Cost Optimization

1. **Intelligent Caching** (60% API reduction)
   - `TTLCache` for claims (credibility.py)
   - `TTLCache` for research results (agent.py)
   - Redis for distributed caching
   - Cache source classifications

2. **Batch Processing** (50% time reduction)
   - `batch_validate_claims()` groups API calls
   - `ThreadPoolExecutor` for parallel extraction
   - Max 10 concurrent requests (PERFORMANCE_CONFIG)

3. **Smart LLM Usage**
   - Heuristics filter 40% of claims from deep analysis
   - Only borderline scores (3.5-7.5) get LLM bias detection
   - Validation only for scores <4.5
   - Estimated savings: 55% of LLM calls

4. **Model Selection**
   - Gemini Flash (cheaper, fast): Scoring & extraction
   - Llama 3.3 70B via Groq: Alternative with free tier
   - Temperature 0.2: Consistent, deterministic outputs

### Current API Usage Estimates:
- **Per Research** (10 sources):
  - Search: 1 Serper call ($0.002)
  - Extraction: 8 LLM calls ($0.008)
  - Scoring: ~5 deep analysis calls ($0.005)
  - Validation: ~3 calls + 3 search ($0.009)
  - Report: 1 LLM call ($0.002)
  - **Total**: ~$0.026/research

- **Per Update**:
  - Extraction: 1 LLM call ($0.001)
  - Scoring: ~2 calls ($0.002)
  - Strategy: 1 LLM call ($0.001)
  - Reconcile: 1 LLM call ($0.001)
  - Report: 1 LLM call ($0.002)
  - **Total**: ~$0.007/update

### Monetization

#### Pricing Tiers:

**Free Tier** ($0/month)
- 10 researches/month
- Basic credibility scoring (heuristics only)
- Standard reports
- Community support (GitHub issues)

**Pro Tier** ($29/month)
- Unlimited researches
- Full LLM-based validation
- Advanced bias detection
- Priority processing (dedicated queue)
- Email support (24h response)
- API access (1K calls/month)
- Export reports (MD/PDF)

**Team Tier** ($99/month)
- Everything in Pro
- 5 team members
- Shared research library
- 10K API calls/month
- Custom source weights
- Slack/Teams integration
- Priority support (4h response)

**Enterprise** (Custom pricing)
- Dedicated infrastructure
- White-label option
- Custom integrations (Salesforce, HubSpot)
- SLA guarantees (99.9% uptime)
- Unlimited API calls
- On-premise deployment
- Custom model fine-tuning
- 24/7 phone support

#### Revenue Projections:

| Month | Free Users | Pro | Team | Enterprise | MRR | Costs | Profit |
|-------|-----------|-----|------|------------|-----|-------|-------- |
| 1-3   | 500       | 20  | 2    | 0          | $778| $500  | $278    |
| 4-6   | 2000      | 100 | 10   | 1          | $4.4K| $1.5K | $2.9K  |
| 7-12  | 5000      | 300 | 30   | 5          | $19K | $5K   | $14K   |
| 13-18 | 10000     | 700 | 80   | 15         | $58K | $15K  | $43K   |


## ğŸ“ˆ Performance Optimization

### Current Performance:
- **Initial research**: 45-60s (depends on Serper latency)
- **Update with file**: 10-20s (75% faster)
- **Credibility scoring**: <1s per claim (heuristics + selective LLM)
- **Report generation**: 5-10s (LLM processing)
- **Cache hit rate**: ~40% (TTL 7200s)

### Future Optimizations:

1. **Model Optimization**
   - Fine-tune Gemini Flash on credibility tasks
   - Reduce temperature to 0.1 for consistency
   - Use streaming for long reports

2. **Database Layer**
   - PostgreSQL for persistent storage
   - Index on (topic, timestamp)
   - Materialized views for common queries

3. **Advanced Caching**
   - Redis cluster for distributed cache
   - Cache warming on popular topics
   - Predictive pre-caching

4. **Query Optimization**
   - Debounce research requests (prevent duplicates)
   - Query de-duplication
   - Smart query expansion

## ğŸ”’ Security Considerations

1. **API Key Protection**
   - Environment variables only (`.env` file)
   - Never logged or exposed in UI
   - Rotation every 90 days

2. **Input Validation**
   - File upload type checking 
   - File size limits (10MB max)
   - Content sanitization (no code execution)

3. **Rate Limiting**
   - Per-user request limits (free: 10/month)
   - IP-based rate limiting (100/hour)
   - API key throttling (1K/month for Pro)

4. **Data Privacy**
   - No PII stored
   - Research results cached temporarily (2h TTL)
   - User can clear cache on demand

5. **Error Handling**
   - No sensitive data in error messages
   - Graceful degradation (fallbacks)
   - Logged errors sanitized


## ğŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/yourusername/research-agent
cd research-agent

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env
# Edit .env with your API keys
```

### Running the Application
```bash
# Start Streamlit app
streamlit run app.py

# Open browser at http://localhost:8501
```

### Usage Flow
1. **Select LLM**: Choose Gemini or Groq model
2. **Enter Topic**: Type research query (e.g., "AI Ethics")
3. **Start Research**: Click "ğŸ” Start Research"
4. **View Report**: Review generated report with credibility scores
5. **Update (Optional)**: Upload .txt/.pdf/.docx file to add new information
6. **Download**: Export report as Markdown

## ğŸ“ Dependencies

```txt
langchain                # LLM orchestration
langchain-google-genai   # Gemini integration
langchain-groq           # Groq integration
google-generativeai      # Gemini API
groq                     # Groq API
python-dotenv            # Environment variables
requests                 # HTTP requests (Serper)
streamlit                # Web UI
cachetools               # TTL caching
```

## ğŸ“„ License

MIT License - see LICENSE file for details

